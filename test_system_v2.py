#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± 2.0
ÙŠØ´Ù…Ù„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©
"""

import requests
import json
import time
import os
from datetime import datetime

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ø§Ø¯Ù…
BASE_URL = "http://localhost:5000"
TIMEOUT = 30

def print_header(title):
    """Ø·Ø¨Ø§Ø¹Ø© Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    print("\n" + "="*60)
    print(f"ğŸ§ª {title}")
    print("="*60)

def print_success(message):
    """Ø·Ø¨Ø§Ø¹Ø© Ø±Ø³Ø§Ù„Ø© Ù†Ø¬Ø§Ø­"""
    print(f"âœ… {message}")

def print_error(message):
    """Ø·Ø¨Ø§Ø¹Ø© Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£"""
    print(f"âŒ {message}")

def print_info(message):
    """Ø·Ø¨Ø§Ø¹Ø© Ø±Ø³Ø§Ù„Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"""
    print(f"â„¹ï¸  {message}")

def test_server_health():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø§Ø¯Ù…"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø§Ø¯Ù…")
    
    try:
        response = requests.get(f"{BASE_URL}/health", timeout=TIMEOUT)
        if response.status_code == 200:
            data = response.json()
            print_success(f"Ø§Ù„Ø®Ø§Ø¯Ù… ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ - Ø§Ù„Ø¥ØµØ¯Ø§Ø±: {data.get('version', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
            return True
        else:
            print_error(f"Ø§Ù„Ø®Ø§Ø¯Ù… Ù„Ø§ ÙŠØ³ØªØ¬ÙŠØ¨ - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print_error(f"Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…: {e}")
        return False

def test_algorithms_endpoint():
    """Ø§Ø®ØªØ¨Ø§Ø± Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ø±Ø¶ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©")
    
    try:
        response = requests.get(f"{BASE_URL}/algorithms", timeout=TIMEOUT)
        if response.status_code == 200:
            data = response.json()
            algorithms = data.get('algorithms', {})
            
            print_success("ØªÙ… Ø¬Ù„Ø¨ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø¨Ù†Ø¬Ø§Ø­")
            print_info(f"Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØµÙ†ÙŠÙ: {len(algorithms.get('classification', []))}")
            print_info(f"Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±: {len(algorithms.get('regression', []))}")
            print_info(f"Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ¬Ù…ÙŠØ¹: {len(algorithms.get('clustering', []))}")
            
            # Ø¹Ø±Ø¶ Ø¨Ø¹Ø¶ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª
            print("\nğŸ“‹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª:")
            for task_type, algos in algorithms.items():
                print(f"\n{task_type.upper()}:")
                for i, algo in enumerate(algos[:5]):  # Ø£ÙˆÙ„ 5 Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª ÙÙ‚Ø·
                    print(f"  {i+1}. {algo}")
                if len(algos) > 5:
                    print(f"  ... Ùˆ {len(algos)-5} Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø£Ø®Ø±Ù‰")
            
            return True
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return False

def test_classification_training():
    """Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ØªØµÙ†ÙŠÙ"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ")
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    train_data = {
        "data_path": "sample_data/iris.csv",
        "target": "species",
        "algorithm": "random_forest",
        "task_type": "classification",
        "test_size": 0.2,
        "random_state": 42,
        "parameters": {
            "n_estimators": 50,
            "max_depth": 5
        }
    }
    
    try:
        print_info("Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØºØ§Ø¨Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©...")
        response = requests.post(f"{BASE_URL}/train", json=train_data, timeout=TIMEOUT*2)
        
        if response.status_code == 200:
            result = response.json()
            print_success("ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
            print_info(f"Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {result.get('model_path')}")
            print_info(f"Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©: {result.get('algorithm')}")
            
            # Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            evaluation = result.get('evaluation', {})
            if 'accuracy' in evaluation:
                print_info(f"Ø§Ù„Ø¯Ù‚Ø©: {evaluation['accuracy']:.4f}")
            
            return result.get('model_path')
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            print_error(f"Ø§Ù„Ø®Ø·Ø£: {response.text}")
            return None
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return None

def test_regression_training():
    """Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù†Ø­Ø¯Ø§Ø±"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±")
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    train_data = {
        "data_path": "sample_data/boston.csv",
        "target": "medv",
        "algorithm": "linear_regression",
        "task_type": "regression",
        "test_size": 0.2,
        "random_state": 42
    }
    
    try:
        print_info("Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ...")
        response = requests.post(f"{BASE_URL}/train", json=train_data, timeout=TIMEOUT*2)
        
        if response.status_code == 200:
            result = response.json()
            print_success("ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
            print_info(f"Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {result.get('model_path')}")
            print_info(f"Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©: {result.get('algorithm')}")
            
            # Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            evaluation = result.get('evaluation', {})
            if 'r2_score' in evaluation:
                print_info(f"Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ­Ø¯ÙŠØ¯ (RÂ²): {evaluation['r2_score']:.4f}")
            if 'mean_squared_error' in evaluation:
                print_info(f"Ù…ØªÙˆØ³Ø· Ù…Ø±Ø¨Ø¹ Ø§Ù„Ø®Ø·Ø£: {evaluation['mean_squared_error']:.4f}")
            
            return result.get('model_path')
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            print_error(f"Ø§Ù„Ø®Ø·Ø£: {response.text}")
            return None
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return None

def test_clustering_training():
    """Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ØªØ¬Ù…ÙŠØ¹"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¬Ù…ÙŠØ¹")
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    train_data = {
        "data_path": "sample_data/iris.csv",
        "algorithm": "kmeans",
        "task_type": "clustering",
        "parameters": {
            "n_clusters": 3,
            "random_state": 42
        }
    }
    
    try:
        print_info("Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ K-means...")
        response = requests.post(f"{BASE_URL}/train", json=train_data, timeout=TIMEOUT*2)
        
        if response.status_code == 200:
            result = response.json()
            print_success("ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
            print_info(f"Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {result.get('model_path')}")
            print_info(f"Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ©: {result.get('algorithm')}")
            
            return result.get('model_path')
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            print_error(f"Ø§Ù„Ø®Ø·Ø£: {response.text}")
            return None
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return None

def test_prediction(model_path, task_type="classification"):
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤"""
    print_header(f"Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ ({task_type})")
    
    if not model_path:
        print_error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªÙ†Ø¨Ø¤")
        return False
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ†Ø¨Ø¤
    if task_type == "classification":
        features = [[5.1, 3.5, 1.4, 0.2], [6.2, 3.4, 5.4, 2.3]]
    elif task_type == "regression":
        features = [[0.00632, 18.0, 2.31, 0, 0.538, 6.575, 65.2, 4.09, 1, 296, 15.3, 396.9, 4.98]]
    else:
        features = [[5.1, 3.5, 1.4, 0.2], [6.2, 3.4, 5.4, 2.3]]
    
    predict_data = {
        "model_path": model_path,
        "features": features
    }
    
    try:
        print_info("Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤...")
        response = requests.post(f"{BASE_URL}/predict", json=predict_data, timeout=TIMEOUT)
        
        if response.status_code == 200:
            result = response.json()
            print_success("ØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù†Ø¬Ø§Ø­")
            print_info(f"Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª: {result.get('predictions')}")
            return True
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            print_error(f"Ø§Ù„Ø®Ø·Ø£: {response.text}")
            return False
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return False

def test_nlp_training():
    """Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ NLP"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©")
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    train_data = {
        "data_path": "sample_data/text_data.csv",
        "text_column": "text",
        "target_column": "label",
        "vectorizer_type": "tfidf",
        "classifier_type": "logistic_regression",
        "use_gridsearch": False,
        "test_size": 0.2,
        "random_state": 42
    }
    
    try:
        print_info("Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ...")
        response = requests.post(f"{BASE_URL}/nlp/train", json=train_data, timeout=TIMEOUT*3)
        
        if response.status_code == 200:
            result = response.json()
            print_success("ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ NLP Ø¨Ù†Ø¬Ø§Ø­")
            print_info(f"Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {result.get('model_path')}")
            print_info(f"Ù†ÙˆØ¹ Ø§Ù„Ù…ØªØ¬Ù‡: {result.get('vectorizer_type')}")
            print_info(f"Ù†ÙˆØ¹ Ø§Ù„Ù…ØµÙ†Ù: {result.get('classifier_type')}")
            print_info(f"Ø§Ù„Ø¯Ù‚Ø©: {result.get('accuracy', 0):.4f}")
            print_info(f"Ø§Ù„ÙØ¦Ø§Øª: {result.get('classes')}")
            
            return result.get('model_path')
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ NLP - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            print_error(f"Ø§Ù„Ø®Ø·Ø£: {response.text}")
            return None
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return None

def test_nlp_prediction(model_path):
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€ NLP"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€ NLP")
    
    if not model_path:
        print_error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ NLP Ù„Ù„ØªÙ†Ø¨Ø¤")
        return False
    
    # Ù†ØµÙˆØµ Ù„Ù„ØªÙ†Ø¨Ø¤
    texts = [
        "Ù‡Ø°Ø§ Ø§Ù„Ù…Ù†ØªØ¬ Ù…Ù…ØªØ§Ø² Ø¬Ø¯Ø§",
        "Ø£Ù†Ø§ ØºÙŠØ± Ø±Ø§Ø¶ÙŠ Ø¨Ø§Ù„Ù…Ø±Ø©",
        "Ù…Ù†ØªØ¬ Ø¹Ø§Ø¯ÙŠ Ù„Ø§ Ø£ÙƒØ«Ø±",
        "Ø®Ø¯Ù…Ø© Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù…ØªØ§Ø²Ø©",
        "ØªÙˆØµÙŠÙ„ Ø¨Ø·ÙŠØ¡ ÙˆØºÙŠØ± Ù…Ù†Ø¸Ù…"
    ]
    
    predict_data = {
        "texts": texts,
        "model_path": model_path
    }
    
    try:
        print_info("Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ...")
        response = requests.post(f"{BASE_URL}/nlp/predict", json=predict_data, timeout=TIMEOUT)
        
        if response.status_code == 200:
            result = response.json()
            print_success("ØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€ NLP Ø¨Ù†Ø¬Ø§Ø­")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            results = result.get('results', [])
            print("\nğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤:")
            for i, res in enumerate(results):
                print(f"  {i+1}. Ø§Ù„Ù†Øµ: {res.get('text', '')[:30]}...")
                print(f"     Ø§Ù„ØªØµÙ†ÙŠÙ: {res.get('prediction', '')}")
                print(f"     Ø§Ù„Ø«Ù‚Ø©: {res.get('confidence', 0):.4f}")
                print()
            
            return True
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€ NLP - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            print_error(f"Ø§Ù„Ø®Ø·Ø£: {response.text}")
            return False
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return False

def test_nlp_preprocessing():
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ø³Ø¨Ù‚Ù‹Ø§"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ø³Ø¨Ù‚Ù‹Ø§")
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    preprocess_data = {
        "data_path": "sample_data/text_data.csv",
        "text_column": "text",
        "output_path": "sample_data/processed_text_data.csv",
        "clean_text": True,
        "remove_stopwords": True
    }
    
    try:
        print_info("Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ...")
        response = requests.post(f"{BASE_URL}/nlp/preprocess", json=preprocess_data, timeout=TIMEOUT*2)
        
        if response.status_code == 200:
            result = response.json()
            print_success("ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¨Ù†Ø¬Ø§Ø­")
            print_info(f"Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {result.get('rows_processed')}")
            print_info(f"Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬: {result.get('output_path')}")
            return True
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            print_error(f"Ø§Ù„Ø®Ø·Ø£: {response.text}")
            return False
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return False

def test_nlp_model_info(model_path):
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†Ù…ÙˆØ°Ø¬ NLP"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†Ù…ÙˆØ°Ø¬ NLP")
    
    if not model_path:
        print_error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ NLP")
        return False
    
    try:
        print_info("Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        response = requests.get(f"{BASE_URL}/nlp/model_info?model_path={model_path}", timeout=TIMEOUT)
        
        if response.status_code == 200:
            result = response.json()
            print_success("ØªÙ… Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­")
            print_info(f"Ø§Ù„Ù…ØªØ¬Ù‡: {result.get('vectorizer')}")
            print_info(f"Ø§Ù„Ù…ØµÙ†Ù: {result.get('classifier')}")
            print_info(f"Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª: {result.get('n_classes')}")
            print_info(f"Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {result.get('model_size_mb', 0):.2f} MB")
            return True
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return False

def test_list_models():
    """Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬"""
    print_header("Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")
    
    try:
        response = requests.get(f"{BASE_URL}/list_models", timeout=TIMEOUT)
        if response.status_code == 200:
            result = response.json()
            models = result.get('models', [])
            print_success(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(models)} Ù†Ù…ÙˆØ°Ø¬")
            
            if models:
                print("\nğŸ“‹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©:")
                for i, model in enumerate(models[:10]):  # Ø£ÙˆÙ„ 10 Ù†Ù…Ø§Ø°Ø¬ ÙÙ‚Ø·
                    print(f"  {i+1}. {model}")
                if len(models) > 10:
                    print(f"  ... Ùˆ {len(models)-10} Ù†Ù…ÙˆØ°Ø¬ Ø¢Ø®Ø±")
            
            return True
        else:
            print_error(f"ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ - Ø±Ù…Ø² Ø§Ù„Ø­Ø§Ù„Ø©: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print_error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        return False

def run_comprehensive_test():
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„"""
    print_header("Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ - Ø§Ù„Ø¥ØµØ¯Ø§Ø± 2.0")
    print(f"â° ÙˆÙ‚Øª Ø§Ù„Ø¨Ø¯Ø¡: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
    test_results = {}
    
    # 1. Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø§Ø¯Ù…
    test_results['server_health'] = test_server_health()
    if not test_results['server_health']:
        print_error("ÙØ´Ù„ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø§Ø¯Ù…. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù… Ø£ÙˆÙ„Ø§Ù‹.")
        return
    
    # 2. Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ø±Ø¶ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª
    test_results['algorithms'] = test_algorithms_endpoint()
    
    # 3. Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    print("\n" + "="*60)
    print("ğŸš€ Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬")
    print("="*60)
    
    # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ
    classification_model = test_classification_training()
    test_results['classification_training'] = classification_model is not None
    
    # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±
    regression_model = test_regression_training()
    test_results['regression_training'] = regression_model is not None
    
    # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¬Ù…ÙŠØ¹
    clustering_model = test_clustering_training()
    test_results['clustering_training'] = clustering_model is not None
    
    # 4. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤
    print("\n" + "="*60)
    print("ğŸ”® Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¨Ø¤")
    print("="*60)
    
    if classification_model:
        test_results['classification_prediction'] = test_prediction(classification_model, "classification")
    
    if regression_model:
        test_results['regression_prediction'] = test_prediction(regression_model, "regression")
    
    if clustering_model:
        test_results['clustering_prediction'] = test_prediction(clustering_model, "clustering")
    
    # 5. Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©
    print("\n" + "="*60)
    print("ğŸ“ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP)")
    print("="*60)
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ø³Ø¨Ù‚Ù‹Ø§
    test_results['nlp_preprocessing'] = test_nlp_preprocessing()
    
    # ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ NLP
    nlp_model = test_nlp_training()
    test_results['nlp_training'] = nlp_model is not None
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù€ NLP
    if nlp_model:
        test_results['nlp_prediction'] = test_nlp_prediction(nlp_model)
        test_results['nlp_model_info'] = test_nlp_model_info(nlp_model)
    
    # 6. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    print("\n" + "="*60)
    print("ğŸ”§ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©")
    print("="*60)
    
    test_results['list_models'] = test_list_models()
    
    # 7. Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print_header("Ù…Ù„Ø®Øµ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±")
    
    total_tests = len(test_results)
    passed_tests = sum(test_results.values())
    failed_tests = total_tests - passed_tests
    
    print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª: {total_tests}")
    print(f"âœ… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {passed_tests}")
    print(f"âŒ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ÙØ§Ø´Ù„Ø©: {failed_tests}")
    print(f"ğŸ“ˆ Ù†Ø³Ø¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­: {(passed_tests/total_tests)*100:.1f}%")
    
    print(f"\nâ° ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    if failed_tests == 0:
        print_success("ğŸ‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù†Ø¬Ø­Øª! Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ø«Ø§Ù„ÙŠ.")
    else:
        print_error(f"âš ï¸  {failed_tests} Ø§Ø®ØªØ¨Ø§Ø± ÙØ´Ù„. Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø£Ø¹Ù„Ø§Ù‡.")
    
    return test_results

if __name__ == "__main__":
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    required_files = [
        "sample_data/iris.csv",
        "sample_data/boston.csv", 
        "sample_data/text_data.csv"
    ]
    
    missing_files = [f for f in required_files if not os.path.exists(f)]
    if missing_files:
        print_error("Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù…ÙÙ‚ÙˆØ¯Ø©:")
        for f in missing_files:
            print(f"  - {f}")
        print_info("ÙŠØ±Ø¬Ù‰ Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª Ù‚Ø¨Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±")
        exit(1)
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„
    run_comprehensive_test() 